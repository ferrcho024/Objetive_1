{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fernando Avila\\anaconda3\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.3, the latest is 0.5.5.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "### Import libraries\n",
    "\n",
    "import General_f as Gf\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "import numpy as np\n",
    "import importlib\n",
    "import wx\n",
    "import DQ_measure_f as DQf\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn' --- Para quitar los warnings de pandas y python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Characterization of Database Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must select an option before the next step.\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(Gf)\n",
    "\n",
    "app = wx.App()\n",
    "dbType = Gf.MyDataBase()\n",
    "dbType.CenterOnScreen()\n",
    "app.SetTopWindow(dbType)\n",
    "app.MainLoop()\n",
    "app.Destroy()\n",
    "\n",
    "if not dbType.ban: \n",
    "    print('You must select an option before the next step.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Characterization of Variable Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid DataFrame entered\n",
      "No file selected\n"
     ]
    }
   ],
   "source": [
    "if not dbType.ban:\n",
    "    print('You must select an option in the step 1.')\n",
    "else:\n",
    "    importlib.reload(Gf)\n",
    "    df,_ = Gf.check_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Gf)\n",
    "\n",
    "app = wx.App()\n",
    "Answers = Gf.MyDims()\n",
    "Answers.CenterOnScreen()\n",
    "app.SetTopWindow(Answers)\n",
    "app.MainLoop()\n",
    "app.Destroy()\n",
    "\n",
    "if not Answers.ban: \n",
    "    print('You must answer the questions before the next step.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Dimension Selection and Weight Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.Destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ideal = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import General_f as Gf\n",
    "import importlib\n",
    "importlib.reload(Gf)\n",
    "import wx\n",
    "\n",
    "app = wx.App()\n",
    "frame = Gf.MyFrame()\n",
    "frame.CenterOnScreen()\n",
    "app.SetTopWindow(frame)\n",
    "app.MainLoop()\n",
    "app.Destroy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(Gf)\n",
    "player = 'Andrea'\n",
    "muestra = df[df['Jugadora'] == player]\n",
    "\n",
    "_,dff = Gf.check_df(muestra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "datos = df.copy()\n",
    "DQ_dim = {}\n",
    "if frame.dimensions['Consistency'] > 0:\n",
    "    cons,noCons,muestra = DQf.consistency(datos, clean=False)\n",
    "    if not pd.isna(cons):\n",
    "        DQ_dim['Consistency'] = cons\n",
    "\n",
    "if frame.dimensions['Diversity'] > 0:\n",
    "    div, _, muestra = DQf.diversity(datos, clean=False)\n",
    "    if not pd.isna(div):\n",
    "        DQ_dim['Diversity'] = div\n",
    "  \n",
    "if frame.dimensions['Completeness'] > 0:\n",
    "    compl, muestra = DQf.completeness(datos, clean=False)\n",
    "    if not pd.isna(compl):\n",
    "        DQ_dim['Completeness'] = compl\n",
    "\n",
    "if frame.dimensions['Duplicity'] > 0:\n",
    "    dup,_,muestra = DQf.duplicity(datos, clean=False)\n",
    "    if not pd.isna(dup):\n",
    "        DQ_dim['Duplicity'] = dup\n",
    "\n",
    "if frame.dimensions['Volume'] > 0:\n",
    "    vol,muestra = DQf.volume(datos, clean=False)\n",
    "    if not pd.isna(vol):\n",
    "        DQ_dim['Volume'] = vol\n",
    "\n",
    "if frame.dimensions['Precision'] > 0:\n",
    "    prec,muestra = DQf.precision(datos)\n",
    "    if not pd.isna(prec):\n",
    "        DQ_dim['Precision'] = prec\n",
    "\n",
    "if frame.dimensions['Outliers'] > 0:\n",
    "    out,muestra = DQf.outliers(datos)\n",
    "    if not pd.isna(out):\n",
    "        DQ_dim['Outliers'] = out   \n",
    "\n",
    "if frame.dimensions['Uncertainty'] > 0:\n",
    "    unc,muestra = DQf.uncertainty(datos)\n",
    "    if not pd.isna(unc):\n",
    "        DQ_dim['Uncertainty'] = unc\n",
    "\n",
    "DQ_Index = 0\n",
    "for d in DQ_dim.keys():\n",
    "    DQ_Index += round((frame.dimensions[d]/sum(frame.dimensions.values())*DQ_dim[d]),2)\n",
    "print(DQ_dim)\n",
    "print('DQ_index:',round(DQ_Index,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dims = list(DQ_dim.keys())\n",
    "dims = [*dims, dims[0]]\n",
    "\n",
    "scores = list(DQ_dim.values())\n",
    "scores = [*scores, scores[0]]\n",
    "\n",
    "label_loc = np.linspace(start=0, stop=2 * np.pi, num=len(dims))\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.subplot(polar=True)\n",
    "plt.plot(label_loc, scores, 'o-')\n",
    "plt.title('Dimensions', size=20)\n",
    "plt.thetagrids(np.degrees(label_loc), labels=dims)\n",
    "plt.fill(label_loc, scores, alpha=0.25)\n",
    "plt.yticks([0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
    "plt.ylim(0,1)\n",
    "#plt.savefig('ideal_lvl1.svg', format='svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pd.Series([1,22,3,4,5,6])\n",
    "res = muestra['Sesion']\n",
    "res.reset_index(inplace=True, drop=True)\n",
    "\n",
    "pd.concat([res, ref], axis=1)\n",
    "#muestra.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df['Sesion'].nunique(dropna=True)/len(df['Sesion'])))\n",
    "\n",
    "\n",
    "((np.log(df['Sesion'].value_counts()/len(df['Sesion']))*(df['Sesion'].value_counts()/len(df['Sesion']))).sum()*-1)/df['Sesion'].nunique(dropna=True)\n",
    "\n",
    "df['Sesion'].values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPARACIÓN CÁLCULO DE DIVERSIDAD\n",
    "# https://ecopy.readthedocs.io/en/latest/diversity.html\n",
    "\n",
    "especies = {'A':1,\n",
    "            'B':200}\n",
    "\n",
    "#########################################\n",
    "# No hay ponderación o pesos/importancia de cada especie\n",
    "mio = (len(especies)/sum(especies.values()))\n",
    "\n",
    "######################################\n",
    "# Hay peso para cada especie de acuerdo con el número de veces que se repite\n",
    "shannon = 0\n",
    "for d in especies:\n",
    "    shannon += (especies[d]/sum(especies.values()))*np.log(especies[d]/sum(especies.values()))\n",
    "\n",
    "shannon = 1 - (abs(shannon)/np.log(len(especies)))\n",
    "\n",
    "######################################\n",
    "# Hay peso para cada especie de acuerdo con el número de veces que se repite\n",
    "gini = 0\n",
    "for d in especies:\n",
    "    gini += (especies[d]/sum(especies.values()))**2\n",
    "\n",
    "gini = 1 - gini\n",
    "\n",
    "######################################\n",
    "# Hay peso para cada especie de acuerdo con el número de veces que se repite\n",
    "simpson = 0\n",
    "for d in especies:\n",
    "    simpson += (especies[d]/sum(especies.values()))**2\n",
    "\n",
    "print('Propuesta:',round(mio,2),'\\nShannon:',round(shannon,2),'\\nGini-Simpson:',round(gini,2),'\\nSimpson:',round(simpson,2),'\\n*********************\\nTOTAL ESPECIES:',len(especies),'\\nTOTAL DATOS:',sum(especies.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "\n",
    "if frame.dimensions['legibility'] > 0:\n",
    "    cons,noCons,muestra = DQf.consistency(muestra, clean=True)\n",
    "    print('Si')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "\n",
    "if frame.dimensions['variability'] > 0:\n",
    "    var, deleted, muestra = DQf.variability(muestra, clean=True)\n",
    "    print('Si')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "\n",
    "if frame.dimensions['completeness'] > 0:\n",
    "    compl, muestra = DQf.completeness(muestra, clean=True)\n",
    "    print('Si')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "\n",
    "if frame.dimensions['redundancy'] > 0:\n",
    "    red,_,muestra = DQf.redundancy(muestra, clean=True)\n",
    "    print('Si')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.dimensions.values()\n",
    "DQ_Index = 0\n",
    "for d, v in zip(frame.dimensions.keys(), [cons, var, compl, red]):\n",
    "    DQ_Index += round((frame.dimensions[d]/sum(frame.dimensions.values())*v),2)\n",
    "    print(round((frame.dimensions[d]/sum(frame.dimensions.values())*v),2), '-', round((frame.dimensions[d]/sum(frame.dimensions.values())),2), '-', v)\n",
    "print('DQ_index:',round(DQ_Index,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "DQf.volume(muestra, clean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "DQf.precision(muestra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(1 - (muestra.std(numeric_only=True)/muestra.mean(numeric_only=True)), columns=['prec'])\n",
    "res['cero'] = 0\n",
    "res['prec'] = res[['cero','prec']].max(axis=1, skipna=False)\n",
    "#res['res'] = max('cero','prec')\n",
    "res['prec'].mean()\n",
    "#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (muestra.isnull().sum(axis=0)/len(muestra))\n",
    "list(res[res>0.5].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "Distancia = ['Selection','Starthour', 'FinalHour', 'Distance(m)','ExplosiveDist(m)','HIBD(m)','[0-45]%(m)','[45-65]%(m)',\n",
    "'[65-75]%(m)','[75-85]%(m)','[85-95]%(m)','[95-100]%(m)','[0-6]km/h(m)','[6-9]km/h(m)','[9-12]km/h(m)','[12-15]km/h(m)',\n",
    "'[15-18]km/h(m)','[18-21]km/h(m)','[21-50]km/h(m)','[0-45]%Cnt','[45-65]%Cnt','[65-75]%Cnt','[75-85]%Cnt','[85-95]%Cnt',\n",
    "'[95-100]%Cnt','[0-6]km/hCnt','[6-9]km/hCnt','[9-12]km/hCnt','[12-15]km/hCnt','[15-18]km/hCnt','[18-21]km/hCnt',\n",
    "'[21-50]km/hCnt','[0-45]%(ms)','[45-65]%(ms)','[65-75]%(ms)','[75-85]%(ms)','[85-95]%(ms)','[95-100]%(ms)','[0-6]km/h(ms)',\n",
    "'[6-9]km/h(ms)','[9-12]km/h(ms)','[12-15]km/h(ms)','[15-18]km/h(ms)','[18-21]km/h(ms)','[21-50]km/h(ms)']\n",
    "\n",
    "Aceleracion =['Selection','Starthour', 'FinalHour','Accelerations','Decelerations','MAXAcc(m/s²)','MAXDec(m/s²)',\n",
    "'AVGAcc(m/s²)','AVGDec(m/s²)','Dif.ACC/DEC','HighAccCnt','HighDecCnt','HighAcc(m)','HighDec(m)','HighAcc(ms)',\n",
    "'HighDec(ms)','[01]m/s²(m)','[12]m/s²(m)','[23]m/s²(m)','[34]m/s²(m)','[45]m/s²(m)','[56]m/s²(m)','[610]m/s²(m)',\n",
    "'[-10]m/s²(m)','[-2-1]m/s²(m)','[-3-2]m/s²(m)','[-4-3]m/s²(m)','[-5-4]m/s²(m)','[-6-5]m/s²(m)','[-10-6]m/s²(m)',\n",
    "'[050]%(m)','[5060]%(m)','[6070]%(m)','[7080]%(m)','[8090]%(m)','[90100]%(m)','[-500]%(m)','[-60-50]%(m)','[-70-60]%(m)',\n",
    "'[-80-70]%(m)','[-90-80]%(m)','[-100-90]%(m)','[01]m/s²Cnt','[12]m/s²Cnt','[23]m/s²Cnt','[34]m/s²Cnt','[45]m/s²Cnt',\n",
    "'[56]m/s²Cnt','[610]m/s²Cnt','[-10]m/s²Cnt','[-2-1]m/s²Cnt','[-3-2]m/s²Cnt','[-4-3]m/s²Cnt','[-5-4]m/s²Cnt','[-6-5]m/s²Cnt',\n",
    "'[-10-6]m/s²Cnt','[050]%Cnt','[5060]%Cnt','[6070]%Cnt','[7080]%Cnt','[8090]%Cnt','[90100]%Cnt','[-500]%Cnt','[-60-50]%Cnt',\n",
    "'[-70-60]%Cnt','[-80-70]%Cnt','[-90-80]%Cnt','[-100-90]%Cnt','[01]m/s²(ms)','[12]m/s²(ms)','[23]m/s²(ms)','[34]m/s²(ms)',\n",
    "'[45]m/s²(ms)','[56]m/s²(ms)','[610]m/s²(ms)','[-10]m/s²(ms)','[-2-1]m/s²(ms)','[-3-2]m/s²(ms)','[-4-3]m/s²(ms)',\n",
    "'[-5-4]m/s²(ms)','[-6-5]m/s²(ms)','[-10-6]m/s²(ms)','[050]%(ms)','[5060]%(ms)','[6070]%(ms)','[7080]%(ms)','[8090]%(ms)',\n",
    "'[90100]%(ms)','[-500]%(ms)','[-60-50]%(ms)','[-70-60]%(ms)','[-80-70]%(ms)','[-90-80]%(ms)','[-100-90]%(ms)']\n",
    "\n",
    "Salud = ['Selection','Starthour', 'FinalHour','HRDuration','MAXHR(bpm)','AVGHR(bpm)','Avg(%ofMax)','HighHR(m)',\n",
    "'HighHRCnt','HighHR(ms)','[50-60]%(m)','[60-70]%(m)','[70-80]%(m)','[80-90]%(m)','[90-100]%(m)','[100-200]%(m)',\n",
    "'[50-60]%Cnt','[60-70]%Cnt','[70-80]%Cnt','[80-90]%Cnt','[90-100]%Cnt','[100-200]%Cnt','[50-60]%(ms)','[60-70]%(ms)',\n",
    "'[70-80]%(ms)','[80-90]%(ms)','[90-100]%(ms)','[100-200]%(ms)']\n",
    "\n",
    "Velocidad = ['Selection','Starthour', 'FinalHour','SprintAbsCnt','SprintRelCnt','HSRAbsCnt','HSRRelCnt','SprintAbs(m)',\n",
    "'SprintRel(m)','HSRAbs(m)','HSRRel(m)','MAXSpeed(km/h)','AVGSpeed(km/h)','SprintmaxCnt','Sprintmax(m)','Sprintmax(ms)',\n",
    "'HSRAbsRep','HSRRelRep','SprintAbsRep','SprintRelRep','SprintmaxRep']\n",
    "\n",
    "Eventos = ['Selection','Starthour', 'FinalHour','Horiz.ImpactsCnt','Stepscount','StepBalance(%)','Jumpscount','JumpsAVGTakeoff(g)',\n",
    "'JumpsAVGLanding(g)','HighTakeoffCnt','HighLandingCnt','Landing[0-3]GCnt','Landing[3-5]GCnt','Landing[5-8]GCnt','Landing[8-100]GCnt',\n",
    "'Takeoff[0-3]GCnt','Takeoff[3-5]GCnt','Takeoff[5-8]GCnt','Takeoff[8-100]GCnt']\n",
    "\n",
    "Frecuencia = ['Selection','Starthour', 'FinalHour','FrecMAX(hz)','FrecAVG(hz)','Hz*GMAX','Hz*GAVG','[0-0,5](ms)',\n",
    "'[0,5-1](ms)','[1-1,5](ms)','[1,5-100](ms)']\n",
    "\n",
    "PlayerLoad = ['Selection','Starthour', 'FinalHour','PlayerLoad','PlayerLoadhorizontal','PlayerLoadvertical',\n",
    "'PlayerLoadantero-posterior','PlayerLoadmedio-lateral',]\n",
    "\n",
    "Energia = ['Selection','Starthour', 'FinalHour','Powermet','PowermetAvg','Edimax','HMLD','HMLDcnt','EnergyExpenditure',\n",
    "'DSL','[10-25,5]w/kg(m)','[25,5-35]w/kg(m)','[35-55]w/kg(m)','[55-100]w/kg(m)','[10-25,5]w/kgCnt','[25,5-35]w/kgCnt',\n",
    "'[35-55]w/kgCnt','[55-100]w/kgCnt','[10-25,5]w/kg(ms)','[25,5-35]w/kg(ms)','[35-55]w/kg(ms)','[55-100]w/kg(ms)',\n",
    "'Signal',]\n",
    "\n",
    "agrupamiento = ['Date', 'Sesion', 'Selection']\n",
    "muestra.set_index(agrupamiento, inplace=True)\n",
    "\n",
    "\n",
    "#seccion.groupby(agrupamiento, group_keys=True)[Distancia].apply(lambda x:x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "_,muestra = DQf.outliers(muestra, clean=True)\n",
    "\n",
    "#seccion[Distancia].plot()\n",
    "#seccion[Distancia].corr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = ['DrillsDuration(t)','Distance(m)','ExplosiveDist(m)','HIBD(m)','Accelerations(#)','MAXAcc(m/s²)','MAXDec(m/s²)','HighAcc(m)','HighDec(m)',\n",
    "          'MAXHR(bpm)','HighHR(ms)','HighHRCnt(#)','MAXSpeed(km/h)','AVGSpeed(km/h)','SprintmaxCnt(#)','Sprintmax(m)','Sprintmax(ms)',\n",
    "          'Stepscount(#)','Jumpscount(#)']\n",
    "\n",
    "filter = list(set(filter) - (set(filter) - set(muestra.columns)))\n",
    "\n",
    "\n",
    "seccion = muestra[filter]\n",
    "seccion['DrillsDuration(t)'] = pd.to_timedelta(seccion['DrillsDuration(t)'].astype(str)).dt.total_seconds()\n",
    "seccion.rename({'DrillsDuration(t)':'DrillsDuration(s)'}, axis=1, inplace=True)\n",
    "_,_,seccion = DQf.redundancy(seccion, clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show high correlated variables as a List\n",
    "threshold_corr = 0.8\n",
    "corr_matrix = seccion.corr(numeric_only=True).abs()\n",
    "high_corr_var = np.where(corr_matrix > threshold_corr)\n",
    "corr_matrix = seccion.corr(numeric_only=True)\n",
    "high_corr_matrix = pd.DataFrame(columns=['Var2','Corr'])\n",
    "for x,y in zip(*high_corr_var):\n",
    "    if x != y and x < y:\n",
    "        high_corr_matrix = pd.concat([high_corr_matrix, pd.DataFrame({\n",
    "                                                                'Var2':corr_matrix.columns[y],\n",
    "                                                                'Corr':corr_matrix.iat[x,y]}, \n",
    "                                                                index=[corr_matrix.columns[x]])], axis = 0, ignore_index = False)\n",
    "\n",
    "#high_corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show high correlated variables as a Matrix\n",
    "alta_corr = pd.DataFrame(np.NaN, columns=high_corr_matrix.Var2.unique(), index=high_corr_matrix.index.unique())\n",
    "for x in range(len(high_corr_matrix)):\n",
    "    row = high_corr_matrix.iloc[[x]].index.values[0]\n",
    "    col = high_corr_matrix.iloc[[x]].Var2.values[0]\n",
    "    alta_corr.at[row,col] = high_corr_matrix.iloc[[x]].Corr.values[0]\n",
    "#alta_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best performance\n",
    "best = seccion.loc[seccion[['Distance(m)']].idxmax()]\n",
    "\n",
    "# Preliminar individual results for each player\n",
    "print('Player:',player)\n",
    "print('')\n",
    "print('****** Best Performance ******')\n",
    "print('Sesion:',best.index[0][1])\n",
    "print('Date:',best.index[0][0].date())\n",
    "for c in seccion.columns:\n",
    "    print(str(c)+':',best[c].max())\n",
    "\n",
    "print('')\n",
    "print('****** Trends ******')\n",
    "res = False\n",
    "for x,y in zip(high_corr_matrix.index, high_corr_matrix.Var2):\n",
    "    print(str(x),'and',str(y)+':','True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some mock data\n",
    "variable1 = 'Accelerations(#)'\n",
    "variable2 = 'MAXHR(bpm)'\n",
    "index = 'Sesion'\n",
    "data1 = seccion.loc[:, :, 'Partido completo'][variable1]\n",
    "data2 = seccion.loc[:, :, 'Partido completo'][variable2]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10,5))\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel(index)\n",
    "ax1.set_ylabel(variable1.split('(')[1][:-1], color=color)\n",
    "ax1.plot(np.sort(data1.index.get_level_values(index)), data1.interpolate(method='linear'), color=color, label=variable1)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.tick_params(axis='x', labelrotation=0)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel(variable2.split('(')[1][:-1], color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(np.sort(data1.index.get_level_values(index)), data2.interpolate(method='linear'), color=color, label=variable2)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.tick_params(axis='x', labelrotation=0)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(data1.index.get_level_values('Sesion'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seccion.xs(('Partido completo',42), level=('Selection', 'Sesion'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "importlib.reload(Gf)\n",
    "completos = df[df['Selection'] == 'Partido completo']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = completos.copy()\n",
    "\n",
    "_,datos = DQf.volume(datos, clean=True)\n",
    "_,noLeg,datos = DQf.consistency(datos, clean=True)\n",
    "_,_,datos = DQf.diversity(datos, clean=True)\n",
    "\n",
    "# Show correlated variables as a List\n",
    "threshold_corr = 0.9\n",
    "corr_matrix = datos.corr(numeric_only=True).abs()\n",
    "corr_var = np.where(corr_matrix > threshold_corr)\n",
    "corr_matrix = datos.corr(numeric_only=True)\n",
    "corr_var_matrix = pd.DataFrame(columns=['Var2','Corr'])\n",
    "for x,y in zip(*corr_var):\n",
    "    if x != y and x < y:\n",
    "        corr_var_matrix = pd.concat([corr_var_matrix, pd.DataFrame({\n",
    "                                                                'Var2':corr_matrix.columns[y],\n",
    "                                                                'Corr':corr_matrix.iat[x,y]}, \n",
    "                                                                index=[corr_matrix.columns[x]])], axis = 0, ignore_index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_corr = pd.DataFrame(np.NaN, columns=corr_var_matrix.Var2.unique(), index=corr_var_matrix.index.unique())\n",
    "for x in range(len(corr_var_matrix)):\n",
    "    row = corr_var_matrix.iloc[[x]].index.values[0]\n",
    "    col = corr_var_matrix.iloc[[x]].Var2.values[0]\n",
    "    var_corr.at[row,col] = corr_var_matrix.iloc[[x]].Corr.values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = 'Distance(m)'\n",
    "filtro = list(corr_var_matrix[corr_var_matrix.index == ref]['Var2'])\n",
    "filtro = [ x for x in filtro if \"]%\" not in x ]\n",
    "#filtro = [filtro[0], ref]\n",
    "filtro.append(ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(corr_var_matrix[['Var2']].itertuples(index=True, name=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import combinations\n",
    "\n",
    "cont = 0\n",
    "#for comb in list(corr_var_matrix[['Var2']].itertuples(index=True, name=None)):\n",
    "for comb in combinations(['Takeoff[8-100]GCnt', 'Hz*GAVG', 'FrecAVG(hz)','SprintRelRep'],2):\n",
    "    comb = list(comb)\n",
    "\n",
    "    x = datos.loc[:, comb].values\n",
    "    x = StandardScaler().fit_transform(x) # normalizing the features\n",
    "\n",
    "    if len(comb) <= 2:\n",
    "        componentes = 2\n",
    "    else:\n",
    "        componentes = 'mle'\n",
    "\n",
    "    normalized_datos = pd.DataFrame(x,columns=comb)\n",
    "\n",
    "    pca_datos = PCA(n_components=componentes)\n",
    "    principalComponents_datos = pca_datos.fit_transform(x)\n",
    "\n",
    "    PCA_cols = [ 'PCA'+str(x+1) for x in range(principalComponents_datos.shape[1])]\n",
    "\n",
    "    principal_datos_Df = pd.DataFrame(data = principalComponents_datos\n",
    "                , columns = PCA_cols)\n",
    "\n",
    "    pca_datos.explained_variance_ratio_.sum(), principalComponents_datos.shape\n",
    "\n",
    "    if cont > 0 and cont <= 20:\n",
    "        targets = list(datos['Posicion'].unique())\n",
    "\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4))\n",
    "        ax1.set_xlabel(comb[0],fontsize=10)\n",
    "        ax1.set_ylabel(comb[1],fontsize=10)\n",
    "        ax1.set_title(\"Principal Component Analysis of Datos\",fontsize=10)\n",
    "\n",
    "        for target in targets:\n",
    "            indicesToKeep = datos['Posicion'] == target\n",
    "            ax1.scatter(principal_datos_Df.loc[indicesToKeep, PCA_cols[0]]\n",
    "                    , principal_datos_Df.loc[indicesToKeep, PCA_cols[1]], s = 25)\n",
    "\n",
    "        ax1.legend(targets,prop={'size': 8})\n",
    "\n",
    "        ax2.set_xlabel(comb[0],fontsize=10)\n",
    "        ax2.set_ylabel(comb[1],fontsize=10)\n",
    "        ax2.set_title(\"Real Values of Datos\",fontsize=10)\n",
    "\n",
    "        for target in targets:\n",
    "            indicesToKeep = datos['Posicion'] == target\n",
    "            ax2.scatter(datos.loc[indicesToKeep, comb[0]]\n",
    "                    , datos.loc[indicesToKeep, comb[1]], s = 25)\n",
    "\n",
    "        ax2.legend(targets,prop={'size': 8})\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    cont += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Hz*GAVG',fontsize=20)\n",
    "plt.ylabel('FrecAVG(hz)',fontsize=20)\n",
    "plt.title(\"Principal Component Analysis of Datos\",fontsize=20)\n",
    "targets = list(datos['Posicion'].unique())\n",
    "\n",
    "for target in targets:\n",
    "    indicesToKeep = datos['Posicion'] == target\n",
    "    plt.scatter(datos.loc[indicesToKeep, 'Hz*GAVG']\n",
    "               , datos.loc[indicesToKeep, 'FrecAVG(hz)'], s = 50)\n",
    "\n",
    "plt.legend(targets,prop={'size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head()\n",
    "\n",
    "interesantes = ['Hz*GAVG', 'FrecAVG(hz)','SprintRelCnt(#)', 'Jumpscount(#)', 'SprintRelRep', 'Takeoff[8-100]GCnt']\n",
    "#datos.columns[datos.columns.str.contains('8-100')]\n",
    "datos[interesantes].corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(DQf)\n",
    "\n",
    "new = 'SprintRelCnt(#)'\n",
    "\n",
    "interesantes = ['Hz*GAVG', 'FrecAVG(hz)','SprintRelCnt(#)', '[0,5-1](ms)', '[1-1,5](ms)', 'Takeoff[3-5]GCnt', 'Takeoff[5-8]GCnt', 'Takeoff[8-100]GCnt', 'StepBalance(%)', 'JumpsAVGTakeoff(g)']\n",
    "#interesantes.append(new)\n",
    "# 'Hz*GAVG' --> PORTERA, PIVOT\n",
    "# 'StepBalance(%)' --> CIERRE\n",
    "# '[1-1,5](ms)' --> ALA, CIERRE\n",
    "# 'Takeoff[3-5]GCnt' --> PIVOT\n",
    "# 'Takeoff[5-8]GCnt' --> ALA, ALA-CIERRE\n",
    "# 'Takeoff[8-100]GCnt' --> ALA-CIERRE, ALA-PIVOT\n",
    "# 'JumpsAVGTakeoff(g)' --> ALA-CIERRE, ALA-PIVOT, ALA, PIVOT(Parcial)\n",
    "# 'SprintRelCnt(#)' --> ALA-PIVOT, ALA\n",
    "# '[0,5-1](ms)'  --> ALA-CIERRE\n",
    "\n",
    "\n",
    "res = datos[interesantes]\n",
    "res['Posicion'] = datos['Posicion']\n",
    "#_,res = DQf.outliers(res, clean=True)\n",
    "\n",
    "targets = list(res['Posicion'].unique())\n",
    "targets.sort()\n",
    "for p,s in zip(targets, range(6)):\n",
    "    indicesToKeep = res['Posicion'] == p\n",
    "    res.loc[indicesToKeep, 'Hz*GAVG'] += s/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "# ax = plt.axes(projection='3d')\n",
    "\n",
    "# ax.set_xlabel('Hz*GAVG',fontsize=10)\n",
    "# ax.set_ylabel('FrecAVG(hz)',fontsize=10)\n",
    "# ax.set_zlabel(new,fontsize=10)\n",
    "\n",
    "targets = list(res['Posicion'].unique())\n",
    "targets.sort()\n",
    "\n",
    "# for target in targets:\n",
    "#     indicesToKeep = res['Posicion'] == target\n",
    "#     ax.scatter3D(res.loc[indicesToKeep, 'Hz*GAVG'],\n",
    "#                  res.loc[indicesToKeep, 'FrecAVG(hz)'],\n",
    "#                  res.loc[indicesToKeep, new], s = 50)\n",
    "\n",
    "# plt.legend(targets,prop={'size': 10})\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Hz*GAVG',fontsize=10)\n",
    "plt.ylabel('FrecAVG(hz)',fontsize=10)\n",
    "plt.title(\"2D interaction\",fontsize=20)\n",
    "\n",
    "for target in targets:\n",
    "    indicesToKeep = res['Posicion'] == target\n",
    "    plt.scatter(res.loc[indicesToKeep, 'Hz*GAVG'],\n",
    "               res.loc[indicesToKeep, 'FrecAVG(hz)'], s = 50)\n",
    "\n",
    "plt.legend(targets,prop={'size': 10})\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.scatter_3d(res, x='Hz*GAVG', y='FrecAVG(hz)', z=new,\n",
    "              color='Posicion', width=1000, height=800, title='3D interaction')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = datos.groupby(['Jugadora','Posicion'])[['Hz*GAVG', 'FrecAVG(hz)', new]].median()#agg(lambda x: pd.Series.mode(x)[0])\n",
    "res.reset_index(['Posicion'], inplace=True)\n",
    "for p,s in zip(targets, range(6)):\n",
    "    indicesToKeep = res['Posicion'] == p\n",
    "    res.loc[indicesToKeep, 'Hz*GAVG'] += s/100\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7563fc23a67347b817ff35caf6513d9bc5c54dd304f53e77ac1192a8a3e8c7a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
